ORM - object relational mapping. bir məntiqdir, bir anlayışdır. bir specification-dur. koddakı(entity) classımızın object-ləri ilə databaza arasında əlaqə qurmağa kömək edir. bizə kömək edir ki, biz əllə bütün sql sorğularımızı yazmayaq, entity class-larımızı yaradaq və sql sorğuları özü icra eləsin. developerin işini rahatlaşdırmaq üçün
müsbət cəhəti - kodu səliqəli edir, boiler plate kodu azaldır, kodu səliqəli edir
mənfi cəhəti - sql ilə kodun arasında bir layer artırmış oluruq, bizim dto-lar entity-lərə map olunur, arada istər istəməz vaxt gedir. arxada onsuzda standart jdbc işləyir. ORM is the approach of taking object-oriented data and mapping to a relational data store
JPA - specification. (interface, abstraction). Jpa bir interface-dir, onun implementationu isə hər hansı bir ORM-dir. misal üçün Hibernate
yəni layer olaraq ən yuxarıda JPA durur, bir aşağıda ORM, bir aşağıda isə sql scriptlər. hətta biz JPA istifadə eləməyib, birbaşa ORM-i çağıra bilərik, amma o bir az çətin olacaq
biz interface StudentRepository extends CrudRepository yazırıq - bax bu interface JPA-dır
sonra kodu run edəndə spring interface StudentRepository-in implementation classının yaradır bu class Hibernate-dir. Hibernate scriptlərinə show-sql edib baxa bilirik
Hibernate - bir ORM-dir. JPA interfeysinin realizasiyasıdır, implementation-dur. Həmçinin ORM-in implementation-dur
Hibernate bir növ sql ilə JPA arasında bir layer yaradır, elə hiberbate-in mənfi cəhəti bu layerin yaranmağıdır
Hibernate sırf Java üçündür. Hibernate-də başqa bir mənfi cəhət n+1 problemidir, amma onun həlli artıq var
ORM isə tək Java üçün deyil, bütün proqramlaşdırma dillərində var
Beləliklə layer olaraq danışsaq. JPA -> Hibernate -> SQL. bu ardıcıllıqla layerlər yaranır
Spring Data JPA - ? Remember, Spring Data JPA always requires a JPA provider such as Hibernate or Eclipse Link, etc.

JPA ilə işləyirsənsə JPA Buddy adında plugin var Intellij Idea-da onu yüklə

Entity classlarımızda @Entity və @Id annotation yazmalıyıq (mandatory). @Id annotation burda cədvəldəki primary key sütununu ifadə edir
Həmçinin Entity classlarımızda @Data işlətmirik, equals və hashCode methodlarına görə. və həmçinin equals və hashCode methodlarımızı özümüz override edirik
Entity classlarımızda @Data qoymuruq (hashcode, equals və toString methodlarına görə. n+1 yaranmasın deyə). @Data qoymaq əvəzinə @Data-nın içində olan annotationları bir bir özümüz əllə classın üzərinə yazırıq. @Getter, @Setter və ən asas @EqualsAndHashCode(of = "id") yazırıq


DTO nədir? nə zaman istifadə olunur? Data Transfer Object
Biz kodda Entity classımızı nə heç vaxt API-dan birbaşa qəbul etməliyik (request parameter kimi), nə də heç vaxt API-dan response kimi entity class qaytarmalıyıq. Bu 2 hissədə Dto işlətməliyik. Səbəb? 1. təhlükəsizlik baxımından, cədvəlin strukturunu verməmək üçün. 2. biz həmişə entity classın bütün sütunlarını qəbul etmirik axı və ya cavabda qaytarmırıq axı

id sütunumuza @GeneratedValue qoya da bilərik, qoymaya da bilərik (misal üçün UID case-də, və ya id-ni özümüz set ediriksə)
@GeneratedValue 4 növü var:
1. idendity - simple autoincrement. özü artır. 1,2,3,4 və s (idendity əslində elə özü arxa planda sequence yaradır)
2. sequence - databazakı sequence-i götürür. ordakı increment rule-a görə hərəkət edir. misal üçün initial value, increment rate ordan götürür
3. auto - bu da idendity kimi özü 1-dən başlayıb tək-tək increment edir, amma arxada nəsə müəyyən logiclər saxlayır deyə performansı aşağı salır (məsləhət görülmür)
4. table - cədvəldə max id-ni tapıb increment edib o dəyəri ora set edir. çox gec işləyəcək (məsləhət görülmür)

field-ləriminiz içində enum varsa orda @Enumerated annotation istifadə edirik
@Enumerated() - heç nə yazmasaq enumdakı ordinal dəyərləri gətirir, yəni 0,1,2,3 və s. databazaya həmin 0,1,2 düşəcək (belə etmə bad practise sayılır)
@Enumerated(String) - belə yazanda isə enum-ın string dəyəri databazaya yazılır (bu yaxşıdır)

Repository: (bunda SOLID-in Interface segrataion-u istifadə edilir)
1. CrudRepository - sırf CRUD əməliyatları üçün
2. PagingAndSortingRepository - sırf pagination və sorting əməliyyatları üçün lazım olan methodlar
3. JpaRepository - CRUD + page and sorting (burda pagable var). Filtering də bizə lazımdırsa onda JPASpecificationExecutor<PaymentEntity> interfaceni də vergül ilə implements edirik. Filtering əməliyyatını etdiyimiz classda isə Specification<PaymentEntity> implements edirik

ümumiyyətlə ierarxiya bu cürdür -> JpaRepository interface extends PagingAndSortingRepository extends CrudRepository extends Repository


application.yml-da jpa qoşanda
1. show-sql: true qoysaq onda o Repository interface-də olan methodların arxada hansı sql script işlətdiyini göstərəcək (dev environmentdə həmişə show-sql = true qoyun ki kodu yazanda özünüz baxın, amma prod environmentdə təbii ki show-sql = false yazın performans itməsin deyə latency verməsin)
devdə yox, amma localda bunu həmişə elə, arxada nəyi çağırır özün görəsən deyə
2. hiberbate: ddl-auto: none - (none is default value here) disable DDL (data definition language) handling for hibernate. entity classlarımıza uyğun olaraq create table, create column filan özü etməsin (recommended)
update - update the schema if necessary (the worst)
create - create the schema and destroy previo (not recommended)
create-drop - create and then destroy the sc (not recommended)
validate - validate the schema, make no changes to the database. validasiya eləsin görək bizim entity structorumuz (table name, column name) databazakı cədvəlləki structurla üst üstə düşürmü (recommended)

yəni bizdə liquibase tərəfdə artıq cədvəllər və ya columnlar create olunubsa hibernate tərəf onu create etməsin. hibernate tərəfdə bizim db-də create olunmuş cədvəli alter edib, yəni korlaya bilər, ona görə məsləhət görülmür - bad practise sayılır, çünki ddl məntiqli işləri (create, alter) onsuzda liquibase ilə edirikdə və həmçinin version kontrol kimi saxlayırıq ki bunu kim edib, bu tip işləri hibernate kimi bir toola (ümumiyyətlə ORM-ə) ötürməyimiz yaxşı deyil, belə şeylər liquibase ilə idarə olunsa yaxşıdır. hibernate-də isə DML-lər (INSERT, UPDATE, DELETE) üçün olsa yaxşıdır.
ya ddl-auto yazmırıq ki ümumiyyətlə default olan none götürsün, ya da validate yazırıq ki, db cədvəl ilə entity classlar arasında (table name-də və ya column name-lərdə) fərqlilik olsa onu validate edib bizə desin. misal üçün cədvələ column əlavə etmişik amma yadımızdan çıxıb kodda o columnu entity classa əlavə etməmişik

Ralations:
1. one-to-one (bu relationda əgər əminik ki bunlar ömür boyu one-to-one qalacaqsa yəni dəyişməyəcəksə), məsləhət görülür ki performansa görə shared primary key istifadə edək. yəni hər iki cədvəldə ortaq primary key olur. hər iki cədvəldə primary key olara id sütunu var və bu iki id sütununu bir birinə bağlayırıq. misal üçün 1 cədvəldə id=5, digər cədvəldə id=5 eyni elementi ifadə edir). one ilə bitən relationda default fetching strategy is EAGER
shared primary keydə ikinci cədvəldə liquibase tərəfdə primary key olan sütuna (adətən adı id olur) həm də foreign key olur. (primaryKey : true, foreignKeyName : fk_table_two_name_to_table_one_name, references : table_one_name(id))
shared primary key-də əsas olmayan entity-ə (ikinci entity-ə) @MapsId annotation qoyuruq
2. one-to-many. many ilə bitən relationda default fetching strategy is LAZY
3. many-to-many. many ilə bitən relationda default fetching strategy is LAZY

bidirectional - ikitərəfli. a (entity) class içərisində composite olaraq b classının obyektini saxlayır və həmçinin b (entity) class içərisində composite olaraq a classının obyektini saxlayır
unidirectional - birtərəfli. a (entity) class içərisində composite olaraq b (entity) classının obyektini saxlayırsan, amma b classında a classının obyektini saxlamırsan

Fetching strategies:
Lazy - a cədvəlindən get sorğusu çəkəndə a-ın içində olan relationlar (joinlər, digər cədvəllər) gəlməyəcək. Ən azından ilk dəfədən (sonra field-field çəkəndə relationlar da gələcək)
Eager - a cədvəlindən get sorğusu çəkəndə a-ın içində olan relationlar (joinlər, digər cədvəllər) gələcək, təbii ki hansının başına EAGER qoymusansa onlar gələcək. field field hərəsinə başqa bir şey qoya bilərsən. eager fetch zamanı bütün cari sütunları və bütün relation cədvəlləri fetch edib (dartıb) əvvəlcədən gətirir. bizə lazım olsa da olmasa da. biz işlətsək də işlətməsək də
bəs bunlardan hansı məsləhət görülür? təbii ki LAZY, performansı nəzərətdə saxlamaq üçün. çünki biz misal üçün post cədvəlinin bir sətrini dartanda mütləq deyilki onun bütün relationlarını da dartaq, bəlkə heç bizə onlar lazım deyil? bəlkə elə təkcə misal üçün post.title sütunu bizə lazımdır?
məsləhət görülürki, həmişə default LAZY qoyub, hansı yerdə ki bizə bütün relationlar lazımdır o zaman 2 üsul var ki, onu EAGER kimi edə bilərik, ya Entity Graph vasitəsilə, ya da Join Fetch vasitəsilə relationları darta bilərik

n+1 problemi - n burda entity classımızda olan relationların sayıdır (yəni join elədiyimiz cədvəllərin sayı), 1 isə elə həmin entity-ni fetch edəndə gələn 1 sətir datadır. yəni 1 elə bizim indi olduğumuz entity classı, n isə həmin entity classının içində olan n dənə digər entity classın fieldləridir (digər relationlar). yəni n orda relation sayıdır, 1 isə bizim əsas cədvəlimizin 1 sətridir. n+1 odurki misal üçün bizdə 1 class var içində də 3 ədəd relation var, yəni n+1 edir 4. biz 1 sorğu gördərəndə o databaza üçün 4 sorğu olacaq, 4 ədəd select olacaq. 1000 sorğu edəndə 4000 sorğu. beləcə databazada yük artır və sorğu sayı artdıqca dözmür çökür. performans issue. sual: n+1 problemi hansı entity-də çıxmaya bilər? cavab: əgər entity-mizdə relation yoxdursa (yəni heç bir one-to-one, one-to-many, many-to-many yoxdursa) n+1 heç vaxt olmayacaq
sual - n+1 problemi hansı fetching strategy-də çıxır? LAZY-də yoxsa EAGER-da? cavab: hər ikisində. LAZY-dədə çıxır, EAGER-də də çıxır. EAGER-də findById verən kimi dərhal bütün relationları gətirir. LAZY-də isə findById verən kimi tək 1 gətirir, amma kodda get digər bir relation yazanda (for example: entity.getComments()) başlayır o relationu da gətirməyə. demək EAGER-da avtomatik-dərhal n+1 problemi çıxır, LAZY-də isə biz get methodunu çağırıqca n+1-lər yaranacaq

Hibernate BUG. one-to-one relationda biz hətta fetch = LAZY yazsaq belə özü standard Data JPA orda EAGER retrieve edir. Bu BUG aradan qaldırmaq üçün hibernate plugin aktivləşdirmək lazımdır: apply plugin: 'org.hibernate.orm'

@JoinTable - misal üçün @ManyToMany relation-da bizə üçüncü bir cədvəl yaratmaq lazım olur. Onda biz @JoinTable annotation işlədirik
@JoinTable(name = "students_courses", joinColumns = @JoinColumn(name = "student_id"), inverseJoinColumns = @JoinColumn(name = "course_id) )

@ManyToMany(mappedBy = "courses") - mappedBy burda ona görə istifadə olunurki, əlavə cədvəl yaranmasın. Yəni @ManyToMany-də biz istəyirik 3 cədvələ yaransın. mappedBy qoymasaq 4 cədvəl yaranacaq. mappedBy-da hər iki entitydə yazmırıq, yalnız iki entity-dən birində yazırıq. Beləliklə birinci entity-də @ManyToMany() yazırıq, ikinci entity-də @ManyToMany(mappedBy = "courses") yazırıq
mappedBy nədir? bidirectional entity-də qarşı tərəfdəki-entitydəki fieldin adını refer edir

@OneToOne-da default EAGER-dir. bəs bilirikki EAGER bizə sərf eləmir. Biz @OneToOne-ı da istəyirik LAZY-yə dəyişək. Nə etməliyik? hə imenni @OneToOne-da bir incəlik var. orda Hibernate-də bug var, @OneToOne-da sən götürüb ora fetch = LAZY yazsan belə o onu dəyişmir, elə default EAGER olaraq da qalır. orda @OneToOne-ın default valuesini dəyişmək üçün əlavə hibernate plugin yükləməlisən
bytecode enhancement
build.gradle faylında

buildscript {
	repositories {
		mavenLocal()
		mavenCentral()
	}
	dependencies {
		classpath "org.hibernate:hibernate-gradle-plugin:5.6.4.Final"
	}
}
apply plugin: 'org.hibernate.orm' (bu plugini apply edirik)
hibernate {
	enhance {
		enableLazyInitialization = true
		enableDirtyTracking = false
		enableAssociationManagement = false
		enableExtendedEnhancement = false
	}
}
bunu edəndə @OneToOne fecthing default EAGER idi, bunu bytecode səviyyəsində özü dəyişib LAZY edir

Hibernatedə biz hansı scriptləri ORM ilə edə bilsək ORM ilə edirik (findById), ORM ilə edə bilmədiklərimizi JPQL - Java Persistance Query Language ilə edirik, JPQL ilə edə bilmədiklərimizi ilə Native Query ilə edirik. Yəni ardıcıllıq belə gedir. JPQL ilə Native Query arasında fərq odurki JPQL-də scriptdə entity classının adını yazırıq və column olaraq entity classının field-lərini yazırıq, yəni java classda yazdığımız adları orda scriptdə istifadə edirik, Native Query-də isə scriptdə databazadakı cədvəlin adını yazırıq. Niyə elə hər yerdə Native Query yazmırıq, JPQL-ə üstünlük veririk? Çünki biz elə ORM-i niyə əvvəldən bəri məsləhət bilirik? boiler plate kodu aşağı salır və əsas da odurki appları gün gəlir bir databazadan başqa bir databazaya migrate etmək istəyirik, onda Native Query-lər bizə problem yaradacaq, Posgresql-dəki Native Query, Oracle-də işləməyə bilər, Oracle-da olan MySql-də. amma JPQL yazanda özü bütün databazalara özü adaptasiya olur

// JPQL example
@Query(value = "SELECT count(p.id) FROM PostEntity p")
Long findPostsCount();

// Native Query example
@Query(nativeQuery = true, value = "SELECT distinct title FROM posts")
List<String> findDistinctTitles();

// JPQL example
@Query(value = "SELECT count(p.id) FROM PostEntity p WHERE p.title =:title")
Long findPostsCountByTitle(String title);


Hibernate Entity LifeCycle
Transient - entity yaratmışıq amma hələ save etməmişik.
var entity = new PostEntity();
repo.save(entity) -> hələ bu sətir yazılmayıb. hələ databazaya düşməyib.
Persistent (Managed) - save edəndə isə artıq bu statedə olur. databazaya məlumat düşdü. həmçinin burda sesiya yaranır deyə. misal üçün bir repo.save yazandan sonra repo.findById yazanda məlumatı artıq managed state-dən gətirir yəni sessiyadan gətirir databaza gedib gətirmir. həmçinin bizim işimiz bitəndə də sesiyanı özü bir növ commit edib bağlayır. yəni bir kodda son sətirdə entity.setName("Rovshan"); yazsaq (yəni bundan sonra repo.save(entity) yazmadan) özün bunu databazaya save edəcək, sessiya bitən zaman
Removed - db-dən sətir siləndə bu state yaranır, bu statedə sətir silinən kimi hibernate sesiyanı dayandırır, kəsir ki, sən bundan sonra heç nə etməyəsən. repo.delete(entity) yazanda yaranan state. close session permamently.
Detached - sesiyanı söndürmək, dayandırmaq (silmədən). misal üçün manageddə dedik ki, repo.findById yazanda məlumatı artıq sesisadan gətirir, databasedan gətirmir, bu Detached-də isə databazadan gətirir, çünki sesiyanı dayandırmışıq. close session temporarely. yəni bu sessiyanı nə vaxtsa yenidən managed stateyə qaytarmaq olur


n+1-in qabağını almaq üçün ilk olaraq həryerdə (daha doğrusu sonu ONE ilə bitən yəni defaultu EAGER olan relationlarda) fetch type LAZY qoyub, sonra əgər lazım olduqca relationları çəkmək:
EntityGraph vasitəsilə, ya da JPQL Join Fetch vasitəsilə relationları darta bilərik. JPQL Join Fetch odurki Repository classında hansısa bir find methodunun yuxarısına özümüz JPQL ilə bir join script yazırıq və join sözündən sonra bir FETCH sözü də yazırıq. (misal: select * from orders o join Fetch order_item oi on o.id = oi.order_id)
EntityGraph isə 2 üsulu var:
1. Entity classının yuxarısına @EntityGraph() annotation qoy,  bura attribute paths ötürürük, hansı relationları EAGER FETCH ilə çəkmək istəyiriksə onları vergül ilə yazırıq. Bu o qədər də yaxşı yol hesab edilmir, çünki bəlkə sizə bir sorğuda bir relation lazım olacaq, digər bir sorğuda başqa bir relation? onda fərqli fərqli EntityGraph-lar qurmalısız, əlavə işlər görməlisiz
2. Repository classında hansısa bir find methodunun yuxarısına @EntityGraph(attibutePaths = {"comments", "detail"} yazırıq, yəni 2 relation qoyuruq arrayın içərisinə. Bu zaman bu methodu çağıranda həmin 2 relation-u da join edib gətirəcək (yəni  EAGER FETCH). mütləq show-sql = true edib scriptlərə özün bax başa düş

EntityGraph-da öz type-si var. 2 tipi var: FETCH (default) and LOAD. Bu type nədir? biz EntityGraph ilə üzdəki n+1-i həll edirik, amma altdakı n+1 qala bilər. Yəni misal üçün biz yuxarıda dedik ki, comments və detail relationlarını da gətir. amma misal üçün comments-in də içində relationlar ola bilər, child entity-lərə də gətirir deyə rekursive şəkildə yenə də n+1 yarana bilər. Type-lar həmin o rekursive relationların FETCH tipini təyin edir. type = FETCH qoyanda, comments-in içindəki digər relationlara biz LAZY yazmışıqsa LAZY, EAGER yazmışıqsa EAGER dartacaq. amma type = LOAD qoysaq onda comments-in içindəki bütün relationları da EAGER dartır gətirir. Yəni FECTH biz yazdığımıza baxır, LOAD isə EAGER gətirir

Beləcə EntityGraph normalda daha məsləhət görülür, amma yuxarıda dediyimiz kimi hətta relationların içində də digər relationlar varsa belə mürəkkəb datalar varsa, EntityGraph type ilə oynamaq lazım gələcəksə, belə hallarda EntityGraph yox elə JPQL Join Fetch işlədə bilərik, yəni find methodumuzun yuxarısına özümüz JPQL join scripti yaza bilərik

EntityGraph bir növ EARGER dartır, amma əlavə sorğu yaratmadan. Yəni 1 select çəkir, joinlər köməyilə. Amma LAZY-də join istifadə olunmur, sorğuları tək tək çəkir, ona görə say çox olur. LAZY-də birinci dəfə təkcə əsas cədvəldən 1 select çəkir, sonra data retrive olunur onun içərisindən sən get edəndə başlayır əlavə sorğuları atmağa (tək-tək selectlər, joinsiz)

cascade = ALL - cascade bizə ralationlarda lazım olur. Bizdə 3 relation varsa və insert into yazırıqsa demək normalda 3 ədəd insert into yazmalıyıq, amma cascade = ALL yazanda biz bir dəfə save methodunu çağırmaqla bu 3 cədvələ insert into edə bilirik.
cascade 6 tipi var toplam: ALL, PERSIST, MERGE, REMOVE, REFRESH, DETACH

@ToString.Exclude
relation fieldlərimiz yuxarısına həmçinin bunu da yazırıq ki, misal üçün kodda log.info(postEntity) verəndə də postEntity-in içərisində gedib relationları çəkib gətirməsin, yəni n+1 yaratmasın
sonra hibernatedə də entity classın içərisində olan digər relationları ToString edib loglamaq olmaz, n+1 probleminə gətirib çıxarır, və ya orda relation varsa hətta @OneToMany relation varsa demək orda List data var yenə də List datanı loglamaq bad practise-dir performans issue yaradır.

1 ədəd save yazıb istəyəndə ki bütün relationları həmin o 1 ədəd save methodunun (yəni cascade = ALL ilə) vasitəsilə save edək, onda əgər unidirectional relationumuz varsa (yəni bir classda relation vermişiksə, amma digər  classda həmin relationu yazmamışıqsa) onda save methodu işləmir, xəta verir. open-in-view = false yazmışdı onu silmək lazım idi ki işləsin və ya savePost methodunun yuxarısına @Transactional annotation qoysaydıq onda işləyəcəkdi
open-in-view = true by default. bu o deməkdirki spring JPA özü sessiyanı başdan sona yəni controllerdən son save methoduna kimi və hatta ondan sonra da təzdən controllerə qayıdıb response verənə kimi sessiyanı açıq saxlayır, (bunu fəsadı performansedir. pisdir), amma hansı ki bizə sessiya əslində sadəcə databazaya yazanda və ya databazadan məlumat oxuyanda lazım idi. ona görə open-in-view = true pisdir. çox vaxt open-in-view = false edirik. OSIV filter antipattern araşdır. amma bir şey də var ki, bu open-in-view = false layihəni başlayanda lap əvvəldən etmək lazımdır, tutaqki layijə 2 ildir yazılır, çoxlu kod var, default open-in-view = true olub, indi siz götürüb open-in-view = false yazsaq, orda kodda relation olan yerlərdə çox şey qırılacaq, siz bir bir o problem çıxan yerləri düzəltməlisiniz. burda bir biclik var ki, biz open-in-view = false eləyəndə hansısa bir kod qırıldısa o hissəni düzəltmək üçün həmin methodun üzərinə @Transactional annotation qoyub problem həll edə bilərik, amma bu pis üsuldursa o ancaq həmin methodu düzəldəcək, digərlərini yox. Onda belə çıxır biz bir bir bütün methodlarımızın üzərinə @Transactional annotation qoymalı olacayıq.


Optimistic lock, pessimistic lock
1. Optimistic lock - yalnız bir sətri (row) locklayır, yalnız 1 row. Cədvələ yeni bir column əlavə edirik. Tutaq ki adı olsun version (bigint datatype). Burda data type olaraq version long da ola bilər, modification_date timestamp da ola bilər və s.
@Version
private Long version;
Bunu qoyanda eyni anda eyni 1 sətrdə 2 fərqli tranzaksiya əgər istəsə ki sətrdə nəyisə update eləsin, baxır ki versiyaları düz gəlmir, onda ikinciyə xəta verir (ObjectOptimisticLockingFailureException). O xətanı da biz özümüz try catch-da tutub istədiyimiz əməliyyatı edə bilərik. Tutaqkı ora kod yaza bilərik ki exception throw eləsin ki misal üçün "zəhmət olmasa təkrar yoxlayın", və ya catch hissədə repo.save() yazıb edə bilərikki həmin tranksiyaza da accept olsun və ya @Retryable annotation qoşa bilərik. Bu bizim biznes tərəfin qərarı ilə tənzimlənir
burda bir növ məntiqi olaraq kodda transaction isolation level-də @Transactional(repetable read) etmiş oluruq. bəs niyə o qədər yaxşı deyil, bu yaxşıdır? çünki orda qoyrusane methodun başına, amma o hadisə olanda rollbackı özün logici tam idarə edə bilmirsən, version-a filan databazada baxa bilmirsən

2. pessimistic lock - bütöv bir cədvəli (table) locklayır. məsləhət görülmür bu. çünki gec işləyir. latency yaradır
burda bir növ məntiqi olaraq kodda transaction isolation level-də @Transactional(serializable) etmiş oluruq
bunun 2 növü var, pessimistic_read: oxumağa icazə var (get), amma yazmağa yox, pessimistic_write: (həm oxumağa, həm də yazmağa icazə yoxdur)
bunu kodda necə edirik? repository interfacemizdə olan methodun (misal üçün findById) başına annotation qoyuruq
@Lock(LockModeType.PESSIMISTIC_READ) və ya PESSIMISTIC_WRITE, PESSIMISTIC_FORCE_INCREMENT qoyuruq. PESSIMISTIC_FORCE_INCREMENT versiyanı 2 ədəd artırır. bir növ double check etmək üçün. çünki guya biz repo.save() edərik burda versiya 1 ədəd artmış olar, ondan sonra kodda yenə başqa sətirlər yazarıq, sonra yenə repo.save() yazarıq, onda PESSIMISTIC_FORCE_INCREMENT bizə lazım olacaq ki, 2 dəfə increment eləsin

senior interview question: bir transaction(REPETABLE_READ) qoysaq onda optimistic_lock-un gördüyü işi görmüş olacayıq. Harda hansını istifadə edək? Niyə optimistic lockun performansı qismən də olsa daha yaxşı olacaq?
cavab: 1-cisi - optimistic lock-u exception ilə tutub biznesə uyğun olaraq istədiyimiz əməliyyatı edə bilərik, 2 - optimistic lock versiya checking-i nə vaxt eləyir? kodda yalnız save yazılan hissədə. amma REPETABLE_READ transactiyası qoysaq method fully həmisə isolated olaraq icra edilir, yəni sırf sətri fullu locklayır, getlərdə də save-lərdə (insert-lər) də (prosesi 1 sətir üçün eyni anda yalnız bir ədəd transaksiyaya endirir). misal üçün user1 və girib eyni sətri get edib baxmaq istəsə, user2 də eyni sətri get edib baxmaq istəsə. optimistic lock burda get-ləri locklamır deyə hər iki user eyni anya transaksiyanı yerinə yetirə biləcək. amma REPETABLE_READ qoysaqdıq bu 2 user bu əməliyyatı tək-tək etməli olacaqdı, bu transaksiyalar paralel getməyəcək, ardıcıl gedəcək

həmçinin non-repetable read problemini manual olaraq özümüz həll etmək istəsək select for update buraxırıq. onda manual özümüz update etmiş oluruq datanı. select for update - variablenin state-ni başlayır izləməyə. son dəyəri götürür.
select for update - variablenin state-ni başlayır izləməyə. son dəyəri götürür. non-repetable read problemini manual olaraq özümüz həll etmək istəsək select for update buraxırıq. onda manual özümüz update etmiş oluruq datanı

Hibernate caching: L1, L2 caching
L1 - default enable = true. əgər eyni sorğular eyni sesiyanın daxilindədirsə L1 caching işə düşür və eyni sorğular üçün databazaya yalnız 1 ədəd sorğu (select) gedir
L2 - default enable = false

methodun içində repo.save() yazanda biz transaksiya-sesiya yaratmış oluruq, proseslər eyni sesiyanın içində gedir.
və ya methodun başına @Transactional annotation qoyanda transaksiya-sesiya yaratmış oluruq, proseslər eyni sesiyanın içində gedir.

public void test(){ // burda db-yə 2 sorğu gedəcək yəni L1 caching işə düşməyəcək, çünki burda 2 sesiya var, sesiyaları hələ birləşdirməmişik
	var account = repo.findById(1L).get();
	var account1 = repo.findById(1L).get();
}

sesiyaları birləşdirmək üçün methodun başına @Transactional annotation qoyuruq
@Transactional // burda artıq L1 caching işə düşür, yəni db-yə yalnız 1 ədəd sorğu gedir, çünki yalnız 1 sesiya var və eyni sorğuları L1 caching keşləyir
public void test(){
	var account = repo.findById(1L).get();
	var account1 = repo.findById(1L).get();
}

sonra burda bir tricky məsələ var ki, əgər methodun başına @Transactional annotation qoymuşuqsa onda ən sonra repo.save() yazmasaq belə sesiya bitəndə yəni method bitəndə özü save edir, yəni autocommit edir
@Transactional // yəni burda özü save edir - balansın üzərinə 44 gəlmiş olur
public void test(){
	var account = repo.findById(1L).get();
	account.setBalance(BigDecimal.valueOf(44));
}

L2 - default enable = false. real olaraq çox istifadə olunmur. ondansa cashing-i redis-lə filan etmək olar
L2 yandırmaq üçün caching provider verməliyik, misal üçün ən məşhuru EHcache, sonra Infinispan, and Caffeine, JBoss, Hazelcast və s. Bunlar library-dir dependency kimi gradle və ya pom.xml-ə əlavə edirik. L1-də biz 1 sessiya (avtomatik 1 method) içərisində keşləyirdiksə, L2-də bir multiple sesiyalar (multiple methods) içərisində keşləyirik. yəni repo.findById(1L).get(); 1 methodda yox, 5 methodun içində yazsaq onların hamısını keşdən gətirəcək, databazadan yox.
Burda sisiyalara REGION-lar veririk. misal üçün REGION A, REGION B və s. tutaqkı 5 dənə methodun başına REGION A yazırıq, bunların sesiyaları hamısı biryerdə keşlənmiş olur, sonra hansı methodun başına REGION B yazsaq onların sesiyaları hamısı bir keşlənmiş olur
dedik L2 cachingin etdiyini redis də edə bilir, hətta yaxşı olar ki, elə redislə edək. interview-da soruşula bilər ki, bir app var orda L2 caching seçilib, qəsdən Redis seçilməyib. Niyə? Cavab: sürətə görə. L2 caching Hibernate-in özündən gəlir deyə daha sürətlidir. Redis isə nə qədər möhtəşəm sürətli bir keşləmə olsada istər istəməz onu özümüz qoşuruq, network-connection məsələləri var ona görə L2-dən gec işləyir

bunu application properties-ə qoyuruq
hibernate.cache.use_second_level_cache=true
hibernate.cache.region.factory_class=org.hibernate.cache.ehcache.EhCacheRegionFactory

bunu entity class-a qoyuruq
@Entity
@Cacheable
@org.hibernate.annotations.Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class Foo {


Cache Concurrency Strategy
Based on use cases, we’re free to pick one of the following cache concurrency strategies:

READ_ONLY: Used only for entities that never change (exception is thrown if an attempt to update such an entity is made). It’s very simple and performative. It’s suitable for static reference data that doesn’t change.
READ_WRITE: This strategy guarantees strong consistency, which it achieves by using ‘soft’ locks. When a cached entity is updated, a soft lock is stored in the cache for that entity as well, which is released after the transaction is committed. All concurrent transactions that access soft-locked entries will fetch the corresponding data directly from the database.
NONSTRICT_READ_WRITE: Cache is updated after the transaction that changed the affected data has been committed. Thus, strong consistency isn’t guaranteed, and there’s a small time window in which stale data may be obtained from the cache. This kind of strategy is suitable for use cases that can tolerate eventual consistency.
TRANSACTIONAL: Cache changes are done in distributed XA transactions. A change in a cached entity is either committed or rolled back in both the database and cache in the same XA transaction.